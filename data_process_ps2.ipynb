{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFL1MAVYKQSm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgXrOWWTKQSo"
      },
      "outputs": [],
      "source": [
        "# Load muc123a\n",
        "part123a = pd.read_csv('/content/muc123a.csv')\n",
        "part123a.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnkF1tyiKQSp"
      },
      "outputs": [],
      "source": [
        "# Create household size column\n",
        "part123a['hsize'] = part123a.groupby(['tinh','huyen','xa','diaban','hoso'])['matv'].transform('max')\n",
        "\n",
        "# Filter to keep only rows where m1ac3 == 1 (household head)\n",
        "part123a.drop(part123a[(part123a['m1ac3'] != 1) | (part123a['m1ac2'] != 1)].index, inplace=True)\n",
        "\n",
        "# Keep only household heads who are male and age â‰¥ 25\n",
        "part123a = part123a[(part123a['m1ac3'] == 1) & (part123a['m1ac2'] == 1) & (part123a['m1ac5'] >= 25)]\n",
        "\n",
        "# We take m123a as the base to merge the labels of other files\n",
        "# Only keep the variables of label and individuals age\n",
        "col123a = ['tinh', 'huyen', 'xa', 'diaban', 'hoso','matv','hsize', 'm1ac2', 'm1ac3', 'm1ac5']\n",
        "\n",
        "# Keep only the selected columns in the dataset\n",
        "part123a = part123a[col123a]\n",
        "\n",
        "# Select the columns from muc123a to create a new dataframe\n",
        "df = part123a[col123a].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC17Diy7KQSq"
      },
      "outputs": [],
      "source": [
        "# Import income file\n",
        "part4a = pd.read_csv('/content/muc4a.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m4ac7: average days work per month, m4ac8: average hours work per day\n",
        "# m4ac11: cash received from main job, m4ac12f: other salary\n",
        "# m4ac21: cash received from secondary job, m4ac22f: other salary 1, m4ac25: other salary 2\n",
        "# m4ac27: average hours per day for secondary job\n",
        "col4a = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'matv', 'm4ac6', 'm4ac7', 'm4ac8',\n",
        "           'm4ac16', 'm4ac17', 'm4ac18', 'm4ac11', 'm4ac12f', 'm4ac21', 'm4ac22f', 'm4ac25']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part4a = part4a[col4a]\n",
        "\n",
        "# Create a new column that sums the selected variables for individual's income\n",
        "part4a['indi_income'] = part4a[['m4ac11', 'm4ac12f','m4ac21', 'm4ac22f', 'm4ac25']].sum(axis=1)\n",
        "\n",
        "# Group by household ID to calculate total household income\n",
        "hh_income = part4a.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'])['indi_income'].sum().reset_index()\n",
        "\n",
        "# Rename column for clarity\n",
        "hh_income.rename(columns={'indi_income': 'HH_Income'}, inplace=True)\n",
        "\n",
        "# Merge household income back into the individual-level dataset\n",
        "part4a = part4a.merge(hh_income, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "# Fill NaN values with zero\n",
        "part4a.fillna(0, inplace=True)\n",
        "\n",
        "# Create a new dataframe to merge all files\n",
        "df = df.merge(part4a, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'matv'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "SYK-hvBS1Z9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCNOmOWtKQSr"
      },
      "outputs": [],
      "source": [
        "# Load household expenditure of food and drinks during holidays (5A1)\n",
        "part5a1 = pd.read_csv('/content/muc5a1.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m5a1c2b: expense bought, m5a1c3b: expense self supplied or received\n",
        "col5a1 = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm5a1c2b', 'm5a1c3b']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part5a1 = part5a1[col5a1]\n",
        "\n",
        "# Group by household ID and sum the expenses\n",
        "exp1 = part5a1.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'])[['m5a1c2b', 'm5a1c3b']].sum().reset_index()\n",
        "\n",
        "# Create a new column for total expense\n",
        "exp1['HH_exp1'] = exp1['m5a1c2b'] + exp1['m5a1c3b']\n",
        "\n",
        "# Merge back to the original dataset\n",
        "part5a1 = part5a1.merge(exp1, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "# Drop duplicates so that each 'hoso' appears only once\n",
        "part5a1 = part5a1.drop_duplicates(subset=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], keep='first')\n",
        "\n",
        "part5a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHU3lVKGKQSr"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part5a1.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn0gXqTvKQSr"
      },
      "outputs": [],
      "source": [
        "# Load household daily expenditure on food and drinks\n",
        "part5a2 = pd.read_csv('/content/muc5a2.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m5a2c6: expense bought, m5a2c10: expense self supplied or received\n",
        "col5a2 = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm5a2c6', 'm5a2c10']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part5a2 = part5a2[col5a2]\n",
        "\n",
        "# Group by household ID and sum the expenses\n",
        "exp2 = part5a2.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'])[['m5a2c6', 'm5a2c10']].sum().reset_index()\n",
        "\n",
        "# Create a new column for total expense\n",
        "exp2['HH_exp2'] = exp2['m5a2c6'] + exp2['m5a2c10']\n",
        "\n",
        "# Merge back to the original dataset\n",
        "part5a2 = part5a2.merge(exp2, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "# Drop duplicates so that each 'hoso' appears only once\n",
        "part5a2 = part5a2.drop_duplicates(subset=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], keep='first')\n",
        "\n",
        "part5a2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMSB7TfTKQSr"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part5a2.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts0q8XGCKQSr"
      },
      "outputs": [],
      "source": [
        "# Load household daily expenditure on nonfood and others\n",
        "part5b1 = pd.read_csv('/content/muc5b1.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m5b1c4: expense recieved, m5b1c5: annual expense\n",
        "col5b1 = ['tinh', 'huyen', 'xa', 'diaban', 'hoso','m5b1c4', 'm5b1c5']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part5b1 = part5b1[col5b1]\n",
        "\n",
        "# Group by household ID and sum the expenses\n",
        "exp3 = part5b1.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'])[['m5b1c4','m5b1c5']].sum().reset_index()\n",
        "\n",
        "# Create a new column for total expense\n",
        "exp3['HH_exp3'] = exp3['m5b1c4'] + exp3['m5b1c5']\n",
        "\n",
        "# Merge back to the original dataset\n",
        "part5b1 = part5b1.merge(exp3, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "# Drop duplicates so that each 'hoso' appears only once\n",
        "part5b1 = part5b1.drop_duplicates(subset=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], keep='first')\n",
        "\n",
        "part5b1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnfZ6G1iKQSs"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part5b1.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkrh2eovKQSs"
      },
      "outputs": [],
      "source": [
        "# Load household annual consumption expenditure\n",
        "part5b2 = pd.read_csv('/content/muc5b2.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m5b2c2: expense bought, m5b2c3: expense self supplied or received\n",
        "col5b2 = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm5b2c2', 'm5b2c3']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part5b2 = part5b2[col5b2]\n",
        "\n",
        "# Group by household ID and sum the expenses\n",
        "exp4 = part5b2.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'])[['m5b2c2', 'm5b2c3']].sum().reset_index()\n",
        "part5b2\n",
        "# Create a new column for total expense\n",
        "exp4['HH_exp4'] = exp4['m5b2c2'] + exp4['m5b2c3']\n",
        "\n",
        "# Merge back to the original dataset\n",
        "part5b2 = part5b2.merge(exp4, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "# Drop duplicates so that each 'hoso' appears only once\n",
        "part5b2 = part5b2.drop_duplicates(subset=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], keep='first')\n",
        "\n",
        "part5b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmDEBbGaKQSs"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part5b2.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyIjPFm-KQSs"
      },
      "outputs": [],
      "source": [
        "# Load other spending that is considered as household expenditure\n",
        "part5b3 = pd.read_csv('/content/muc5b3.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m5b3c2: annual expense\n",
        "col5b3 = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm5b3c2']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part5b3 = part5b3[col5b3]\n",
        "\n",
        "# Group by household ID and sum the expenses\n",
        "exp5 = part5b3.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'])[['m5b3c2']].sum().reset_index()\n",
        "\n",
        "# Create a new column for total expense\n",
        "exp5['HH_exp5'] = exp5['m5b3c2']\n",
        "\n",
        "# Merge back to the original dataset\n",
        "part5b3 = part5b3.merge(exp5, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "# Drop duplicates so that each 'hoso' appears only once\n",
        "part5b3 = part5b3.drop_duplicates(subset=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], keep='first')\n",
        "\n",
        "part5b3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIiH4-JyKQSs"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part5b3.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S7_WxRcKQSs"
      },
      "outputs": [],
      "source": [
        "# Load household's accomodation expenditure\n",
        "part7 = pd.read_csv('/content/muc7.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m7c15: land or house/flat leasing\n",
        "# m7c32: annual water expense, m7c36: annual electricity expense , m7c39: annual garbage collection expense\n",
        "col7 = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm7c15', 'm7c32', 'm7c36', 'm7c39']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part7 = part7[col7]\n",
        "\n",
        "# Calculate total housing expense\n",
        "part7['HH_exp6'] = part7['m7c32'] + part7['m7c36'] + part7['m7c39']\n",
        "\n",
        "part7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL7WYHqDKQSs"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part7.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sQrZe-YKQSt"
      },
      "outputs": [],
      "source": [
        "# Import household fixed assets (6A)\n",
        "part6a = pd.read_csv('/content/muc6a.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m6ac3: quantity of the assets, m6ac6: assets' value at current price, m6ac7: percentage of ownership\n",
        "part6a['m6ac7'] = part6a['m6ac7'] / 100\n",
        "col6a = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm6ac3', 'm6ac6', 'm6ac7']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part6a = part6a[col6a].fillna(0)\n",
        "\n",
        "# Calculate total household fixed assets wealth\n",
        "part6a['HH_wealth1'] = part6a['m6ac3'] * part6a['m6ac6'] * part6a['m6ac7']\n",
        "\n",
        "# Aggregate total wealth by household\n",
        "hh_wealth1 = part6a.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'], as_index=False)['HH_wealth1'].sum()\n",
        "\n",
        "# Import household durable goods (6B)\n",
        "part6b = pd.read_csv('/content/muc6b.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m6bc3: quantity of the durable appliance, m6bc6: durable appliance value at current price\n",
        "col6b = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm6bc3', 'm6bc6']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part6b = part6b[col6b].fillna(0)\n",
        "\n",
        "# Calculate total household durable appliance wealth\n",
        "part6b['HH_wealth2'] = part6b['m6bc3'] * part6b['m6bc6']\n",
        "\n",
        "# Aggregate total durable appliance wealth by household\n",
        "hh_wealth2 = part6b.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'], as_index=False)['HH_wealth2'].sum()\n",
        "\n",
        "# Merge wealth data into df\n",
        "df = df.merge(hh_wealth1, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "df = df.merge(hh_wealth2, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "# Fill missing values with 0 (in case some households have no assets or durable goods)\n",
        "df[['HH_wealth1', 'HH_wealth2']] = df[['HH_wealth1', 'HH_wealth2']].fillna(0)\n",
        "\n",
        "# Calculate total household wealth\n",
        "df['HH_Wealth'] = df['HH_wealth1'] + df['HH_wealth2']\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m_0IHeJKQSt"
      },
      "outputs": [],
      "source": [
        "# Import household fixed assets (6A)\n",
        "part6a = pd.read_csv('/content/muc6a.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m6ac3: quantity of the assets, m6ac6: assets' value at current price , m6ac7: percentage of ownership\n",
        "part6a['m6ac7'] = part6a['m6ac7']/100\n",
        "col6a = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm6ac3', 'm6ac6', 'm6ac7']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part6a = part6a[col6a]\n",
        "part6a.fillna(0, inplace=True)\n",
        "\n",
        "# Calculate total household assets\n",
        "part6a['HH_wealth1'] = part6a['m6ac3'] * part6a['m6ac6'] * part6a['m6ac7']\n",
        "\n",
        "# Group by household to get total wealth per household\n",
        "hh_wealth1 = part6a.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'], as_index=False)['HH_wealth1'].sum()\n",
        "\n",
        "# Merge back to the original dataset\n",
        "part6a = part6a.merge(hh_wealth1, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "part6a.drop_duplicates(subset=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], keep='first', inplace=True)\n",
        "\n",
        "part6a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE6yX00XKQSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a58be4-40bb-42c3-af28-9910284e1429"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'part6a' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-96a9fea629b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a new dataframe to merge all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart6a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tinh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'huyen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diaban'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hoso'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'part6a' is not defined"
          ]
        }
      ],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part6a.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpRn1osdKQSt"
      },
      "outputs": [],
      "source": [
        "# Import household durable goods (6B)\n",
        "part6b = pd.read_csv('/content/muc6b.csv')\n",
        "\n",
        "# Define the required columns (household identifiers + selected variables)\n",
        "# m6bc3: quantity of the durable applicance, m6bc6: durable appliance value at current price\n",
        "col6b = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'm6bc3', 'm6bc6']\n",
        "\n",
        "# Filter the dataset to keep only the selected columns\n",
        "part6b = part6b[col6b]\n",
        "part6b.fillna(0, inplace=True)\n",
        "\n",
        "# Calculate total durable goods value of household\n",
        "part6b['HH_wealth2'] = part6b['m6bc3'] * part6b['m6bc6']\n",
        "\n",
        "# Group by household to get total wealth per household\n",
        "hh_wealth2 = part6b.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso'], as_index=False)['HH_wealth2'].sum()\n",
        "\n",
        "# Merge back to the original dataset\n",
        "part6b = part6b.merge(hh_wealth2, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "\n",
        "part6b.drop_duplicates(subset=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], keep='first', inplace=True)\n",
        "\n",
        "part6b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK0upZUZKQSt"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe to merge all files\n",
        "df = part6b.merge(df, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysbbRekfKQSt"
      },
      "outputs": [],
      "source": [
        "df['HH_Wealth'] = df['HH_wealth1'] + df['HH_wealth2']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH-9vA5bKQSt"
      },
      "outputs": [],
      "source": [
        "# m4ac6: working months annually (first),  m4ac7: average days work per month (first), m4ac8: average hours work per day (first)\n",
        "# m4ac16: working months annually (secondary),  m4ac17: average days work per month (secondary), m4ac18: average hours work per day (secondary)\n",
        "# m4ac11: cash received from main job, m4ac12f: other salary\n",
        "# m4ac21: cash received from secondary job, m4ac22f: other salary 1, m4ac25: other salary 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueCGbzqPKQSu"
      },
      "outputs": [],
      "source": [
        "df.to_csv('output.csv',index=False, encoding = 'utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('output2.csv',index=False, encoding = 'utf-8-sig')"
      ],
      "metadata": {
        "id": "6S6odbFhQW5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Xe1BBN4l01ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns for clarity\n",
        "df = df.rename(columns={\"m1ac5\": \"age\"})\n",
        "# Compute log income\n",
        "df[\"log_income\"] = np.log(df[\"HH_Income\"].replace(0, np.nan))\n",
        "\n",
        "# Group by age and compute average log income\n",
        "log_income_by_age = df.groupby(\"age\")[\"log_income\"].mean().reset_index()\n",
        "\n",
        "# Exponentiate the averaged log income\n",
        "Gt = np.exp(log_income_by_age)\n",
        "\n",
        "process_df = pd.DataFrame({\n",
        "    \"age\": log_income_by_age[\"age\"],\n",
        "    \"Gt\": Gt[\"log_income\"]\n",
        "})\n",
        "process_df"
      ],
      "metadata": {
        "id": "hyMCGE2_6Eon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting (with extreme ages included)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(process_df[\"age\"], process_df[\"Gt\"], color='orange', marker='o', linestyle='-')\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(r\"$G_t$ (exp. of avg. log income)\")\n",
        "plt.title(\"Pattern of $G_t$ Across Age\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UTUv3KQI2ZnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_df.to_csv('data3.csv',index=False, encoding = 'utf-8-sig')"
      ],
      "metadata": {
        "id": "k2rIsBZu6nRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.column"
      ],
      "metadata": {
        "id": "bZstxo_BD9nV",
        "outputId": "45473acc-fe43-4fd3-8fb0-02f0592c7067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1031965220f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load muc4a\n",
        "m4a = pd.read_csv(os.path.join('muc4a.csv'))\n",
        "\n",
        "# Select necessary columns\n",
        "columns4a = ['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'matv',\n",
        "             'm4ac6', 'm4ac7', 'm4ac8',  # primary job\n",
        "             'm4ac16', 'm4ac17', 'm4ac18',  # secondary job\n",
        "             'm4ac11', 'm4ac12f', 'm4ac21', 'm4ac22f', 'm4ac25']\n",
        "\n",
        "m4a = m4a[columns4a]\n",
        "\n",
        "# Calculate primary and secondary job working hours\n",
        "m4a['primary_hours'] = m4a['m4ac6'] * m4a['m4ac7'] * m4a['m4ac8']\n",
        "m4a['secondary_hours'] = m4a['m4ac16'] * m4a['m4ac17'] * m4a['m4ac18']\n",
        "\n",
        "# Total annual working hours per individual\n",
        "m4a['total_hours'] = m4a[['primary_hours', 'secondary_hours']].sum(axis=1)\n",
        "\n",
        "# Income per individual\n",
        "m4a['indi_income'] = m4a[['m4ac11', 'm4ac12f','m4ac21', 'm4ac22f', 'm4ac25']].sum(axis=1)\n",
        "\n",
        "# Remove cases: working hours > 0 but income == 0\n",
        "m4a.dropna(subset=['total_hours', 'indi_income'], inplace=True)\n",
        "m4a = m4a[~((m4a['total_hours'] > 0) & (m4a['indi_income'] == 0))]\n",
        "m4a['is_working'] = m4a['total_hours'] > 0\n",
        "\n",
        "# Aggregate to household level\n",
        "hh_agg = m4a.groupby(['tinh', 'huyen', 'xa', 'diaban', 'hoso']).agg(\n",
        "    total_hours=('total_hours', 'sum'),\n",
        "    total_income=('indi_income', 'sum'),\n",
        "    num_workers=('is_working', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Merge with household size\n",
        "hh_agg = hh_agg.merge(df[['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'hsize']].drop_duplicates(),\n",
        "                      on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='left')\n",
        "hh_info = df[['tinh', 'huyen', 'xa', 'diaban', 'hoso', 'hsize']].drop_duplicates()\n",
        "hh_info = hh_info.dropna(subset=['hsize'])  #Drop missing hsize\n",
        "hh_agg = hh_agg.merge(hh_info, on=['tinh', 'huyen', 'xa', 'diaban', 'hoso'], how='inner')\n",
        "\n",
        "# Filter households with workers and compute avg hours per worker\n",
        "hh_agg = hh_agg[hh_agg['num_workers'] > 0]\n",
        "hh_agg['avg_hours_per_worker'] = hh_agg['total_hours'] / hh_agg['num_workers']\n",
        "\n",
        "# Normalize working hours (260 days x 16 hours/day)\n",
        "hh_agg['normalized_hours'] = hh_agg['avg_hours_per_worker'] / (260 * 16)\n",
        "\n",
        "# Final filter\n",
        "hh_agg = hh_agg[(hh_agg['total_income'] > 0) & (hh_agg['normalized_hours'] > 0)]\n",
        "print(hh_agg)\n",
        "\n"
      ],
      "metadata": {
        "id": "FL-hbev68516"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}